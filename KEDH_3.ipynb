{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in input a dict where each key is the given word and the value is your definition of that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'politics':' governance of a nation','justice':'act of righteousness','food':'substance consumed to provide nourishment','patience':'capacity to tolerate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get from WordNet the list of synsets and definitions related to each single input word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('politics.n.01'),\n",
       " Synset('politics.n.02'),\n",
       " Synset('politics.n.03'),\n",
       " Synset('politics.n.04'),\n",
       " Synset('politics.n.05')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social relations involving intrigue to gain authority or power\n",
      "the study of government of states and other political units\n",
      "the profession devoted to governing and to political affairs\n",
      "the opinion you hold with respect to political questions\n",
      "the activities and affairs involved in managing a state or a government\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('politics.n.01').definition())\n",
    "print(wn.synset('politics.n.02').definition())\n",
    "print(wn.synset('politics.n.03').definition())\n",
    "print(wn.synset('politics.n.04').definition())\n",
    "print(wn.synset('politics.n.05').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('justice.n.01'),\n",
       " Synset('justice.n.02'),\n",
       " Synset('judge.n.01'),\n",
       " Synset('department_of_justice.n.01')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('justice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quality of being just or fair\n",
      "judgment involved in the determination of rights and the assignment of rewards and punishments\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('justice.n.01').definition())\n",
    "print(wn.synset('justice.n.02').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('food.n.01'), Synset('food.n.02'), Synset('food.n.03')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any substance that can be metabolized by an animal to give energy and build tissue\n",
      "any solid substance (as opposed to liquid) that is used as a source of nourishment\n",
      "anything that provides mental stimulus for thinking\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('food.n.01').definition())\n",
    "print(wn.synset('food.n.02').definition())\n",
    "print(wn.synset('food.n.03').definition())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('patience.n.01'), Synset('solitaire.n.04')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('patience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good-natured tolerance of delay or incompetence\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('patience.n.01').definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare words (i.e. tokens) of each couple of definitions (without consider stopwords!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['any', 'substance', 'that', 'can', 'be', 'metabolized', 'by', 'an', 'animal', 'to', 'give', 'energy', 'and', 'build', 'tissue']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.word_tokenize(wn.synset('food.n.01').definition())   #tokenize with stop words\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['substance', 'metabolized', 'animal', 'give', 'energy', 'build', 'tissue']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = wn.synset('food.n.01').definition()\n",
    "text_tokens = word_tokenize(text)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()] #tokenize without stopwords\n",
    "\n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Use the two grammars provided below to write 2 sentences for each of them and\n",
    "generate the related Parse Trees using NLTK’s Recursive Descent Parser (top-down\n",
    "method parser):\n",
    "Write a Python script that is able to:\n",
    "➢ load the specific parser with one of the two grammars\n",
    "➢ get the parse tree of a sentence given in input to the parser\n",
    "➢ print the parse tree on the terminal\n",
    "➢ draw the parse tree\n",
    "➢ (see an example of results in the next slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "      print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [(\"Marry\", \"NP\"), (\"saw\", \"V\"), (\"Bob\", \"NP\")]\n",
    "\"\"\"NP: {<DT>?<JJ>*<NN>}\n",
    "VP: {<V>?<NP>*<NN>}\"\"\"\n",
    "NPChunker = nltk.RegexpParser(pattern)\n",
    "result = NPChunker.parse(sentence)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Det Nom | PropN\n",
    "Nom -> Adj Nom | N\n",
    "VP -> V Adj | V NP | V S | V NP PP\n",
    "PP -> P NP\n",
    "PropN -> \"Buster\" | \"Chatterer\" | \"Joe\"\n",
    "Det -> \"the\" | \"a\"\n",
    "N -> \"bear\" | \"squirrel\" | \"tree\" | \"fish\"\n",
    "Adj -> \"angry\" | \"frightened\" | \"little\" | \"tall\"\n",
    "V -> \"chased\" | \"said\" | \"thought\" | \"was\" | \"put\"\n",
    "P -> \"on\"\n",
    "\"\"\")\n",
    "sent = \"bear chased fish\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar2)\n",
    "for tree in rd_parser.parse(sent):\n",
    "      print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
